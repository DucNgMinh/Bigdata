{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType,StructField, StringType, LongType\n",
    "import pyspark.sql.functions as psf\n",
    "from Buoi_4_ETL import ETL_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").getOrCreate()\n",
    "read_path = r'C:\\\\Users\\\\ADMIN\\\\PycharmProjects\\\\Bigdata-1\\\\Data\\\\Dataset\\\\log_content\\\\'\n",
    "save_path = r\"C:\\\\Users\\\\ADMIN\\\\PycharmProjects\\\\Bigdata-1\\\\Data\\Dataset\\\\Clean_data\\\\\"\n",
    "file_name = '20220401'\n",
    "date = '2022-04-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- Type: string (nullable = false)\n",
      " |-- Giải Trí: long (nullable = true)\n",
      " |-- Phim Truyện: long (nullable = true)\n",
      " |-- Thiếu Nhi: long (nullable = true)\n",
      " |-- Thể Thao: long (nullable = true)\n",
      " |-- Truyền Hình: long (nullable = true)\n",
      " |-- Date: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('Contract', StringType(), True), \n",
    "    StructField('Type', StringType(), False), \n",
    "    StructField('Giải Trí', LongType(), True), \n",
    "    StructField('Phim Truyện', LongType(), True), \n",
    "    StructField('Thiếu Nhi', LongType(), True), \n",
    "    StructField('Thể Thao', LongType(), True), \n",
    "    StructField('Truyền Hình', LongType(), True), \n",
    "    StructField('Date', StringType(), False)])\n",
    "\n",
    "monthly_df = spark.createDataFrame(emptyRDD,schema)\n",
    "monthly_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n",
      "------------------------------\n",
      "Read data from HDFS\n",
      "------------------------------\n",
      "Transforming data\n",
      "------------------------------\n",
      "------------------------------\n",
      "Pivoting data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start_date, end_date = \"2022-04-01\", \"2022-04-30\"\n",
    "\n",
    "day_range = pd.period_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "day_list = [day.strftime(\"%Y-%m-%d\") for day in day_range]\n",
    "filename_list = [day.strftime(\"%Y%m%d\") for day in day_range]\n",
    "\n",
    "for i in range(len(day_list)):\n",
    "    date = day_list[i]\n",
    "    file_name = filename_list[i]\n",
    "\n",
    "    ETL = ETL_daily(spark)\n",
    "    ETL.load_data(read_path, file_name)\n",
    "    merge_df = ETL.transform_data(date)\n",
    "    monthly_df = monthly_df.union(merge_df)\n",
    "    # ETL.save_data(save_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- Type: string (nullable = false)\n",
      " |-- Giải Trí: long (nullable = true)\n",
      " |-- Phim Truyện: long (nullable = true)\n",
      " |-- Thiếu Nhi: long (nullable = true)\n",
      " |-- Thể Thao: long (nullable = true)\n",
      " |-- Truyền Hình: long (nullable = true)\n",
      " |-- Date: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthly_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      Date|  count|\n",
      "+----------+-------+\n",
      "|2022-04-01|1483420|\n",
      "|2022-04-02|1470096|\n",
      "|2022-04-03|1448363|\n",
      "|2022-04-04|1448944|\n",
      "|2022-04-05|1442091|\n",
      "|2022-04-06|1443856|\n",
      "|2022-04-07|1443485|\n",
      "|2022-04-08|1440827|\n",
      "|2022-04-09|1444540|\n",
      "|2022-04-10|1407723|\n",
      "|2022-04-11|1464487|\n",
      "|2022-04-12|1430434|\n",
      "|2022-04-13|1448919|\n",
      "|2022-04-14|1438174|\n",
      "|2022-04-15|1447543|\n",
      "|2022-04-16|1493387|\n",
      "|2022-04-17|1467775|\n",
      "|2022-04-18|1431460|\n",
      "|2022-04-19|1449971|\n",
      "|2022-04-20|1434339|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthly_df.groupBy('Date').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_summary = monthly_df.groupBy('Contract').agg(sum('Giải Trí').alias('Giai_Tri'),\n",
    "                                   sum('Phim Truyện').alias('Phim_Truyen'),\n",
    "                                   sum('Thiếu Nhi').alias('Thieu_Nhi'),\n",
    "                                   sum('Thể Thao').alias('The_Thao'),\n",
    "                                   sum('Truyền Hình').alias('Truyen_Hinh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+--------------------+------------------+-----------------+--------------------+----------+\n",
      "| Contract|Giai_Tri_Duration|Phim_Truyen_Duration|Thieu_Nhi_Duration|The_Thao_Duration|Truyen_Hinh_Duration|most_match|\n",
      "+---------+-----------------+--------------------+------------------+-----------------+--------------------+----------+\n",
      "|HTFD11598|             null|               15551|              null|             null|               42919|   42919.0|\n",
      "|HPFD48556|               69|                null|              null|             null|             1468328| 1468328.0|\n",
      "|NBFD10014|             null|                null|              null|             null|             1596494| 1596494.0|\n",
      "|HNH619088|             null|               77275|             11361|             null|              917930|  917930.0|\n",
      "|HNH036174|             null|               62674|              null|             null|              354879|  354879.0|\n",
      "|DNH067877|             null|                null|              null|             null|              181308|  181308.0|\n",
      "|SGH806190|             null|                null|              null|             null|              217779|  217779.0|\n",
      "|HNH582022|             null|                null|              null|             null|             2209949| 2209949.0|\n",
      "|HNH795510|             null|               30197|               265|             null|             1196936| 1196936.0|\n",
      "|DNFD91557|             null|                null|              null|             null|               95567|   95567.0|\n",
      "+---------+-----------------+--------------------+------------------+-----------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_summary.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minf = lit(float(\"-inf\"))\n",
    "row_max = greatest(*[coalesce(col(x), minf) for x in month_summary.columns[1:6]])\n",
    "cond = \"when\" + \".when\".join([\"(col('\" + c + \"') == col('max_value'), lit('\" + c + \"'))\" for c in month_summary.columns[1:6]])\n",
    "\n",
    "month_summary = month_summary.withColumn(\"max_value\", row_max).withColumn(\"most_watch\", eval(cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_summary = month_summary.withColumn(\"taste\", array(*[when(col(c).isNull(), lit(c)) for c in month_summary.columns[1:6]])).withColumn(\"taste\", expr(\"filter(taste, x -> x is not null)\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
