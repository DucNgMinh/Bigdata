{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"4g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = spark.read.format('csv').option('header','true').load('Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = spark.read.csv(path='Advertising.csv',\n",
    "#                sep=',',\n",
    "#                encoding='UTF-8',\n",
    "#                comment=None,\n",
    "               header=True,\n",
    "               inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TV='230.1', Radio='37.8', Newspaper='69.2', Sales='22.1'),\n",
       " Row(TV='44.5', Radio='39.3', Newspaper='45.1', Sales='10.4'),\n",
       " Row(TV='17.2', Radio='45.9', Newspaper='69.3', Sales='9.3'),\n",
       " Row(TV='151.5', Radio='41.3', Newspaper='58.5', Sales='18.5'),\n",
       " Row(TV='180.8', Radio='10.8', Newspaper='58.4', Sales='12.9')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TV: string (nullable = true)\n",
      " |-- Radio: string (nullable = true)\n",
      " |-- Newspaper: string (nullable = true)\n",
      " |-- Sales: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+\n",
      "|   TV|Radio|Newspaper|\n",
      "+-----+-----+---------+\n",
      "|230.1| 37.8|     69.2|\n",
      "| 44.5| 39.3|     45.1|\n",
      "| 17.2| 45.9|     69.3|\n",
      "|151.5| 41.3|     58.5|\n",
      "|180.8| 10.8|     58.4|\n",
      "+-----+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select('TV', 'Radio', 'Newspaper').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill None\n",
    "my_list = [['male', 1, None], ['female', 2, 3],['male', 3, 4]]\n",
    "ds1 = spark.createDataFrame(my_list, ['A', 'B', 'C'])\n",
    "ds1 = ds1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|  0|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  1|  1|  0|\n",
      "|  0|  2|  3|\n",
      "|  1|  3|  4|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace values\n",
    "ds1.na.replace(['male','female'],['1','0']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns   \n",
    "mapping = {'Newspaper': 'C',\n",
    "           'Sales': 'D'}\n",
    "\n",
    "new_names = [mapping.get(col,col) for col in ds1.columns]\n",
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|  0|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds1.toDF(*new_names).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|  0|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds1.withColumnRenamed('Newspaper', 'Paper').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|  0|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop Column\n",
    "drop_name = ['Newspaper', 'Sales']\n",
    "ds1.drop(*(drop_name)).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|120.2| 19.6|     11.6| 13.2|\n",
      "|  8.6|  2.1|        1|  4.8|\n",
      "|214.7|   24|        4| 17.4|\n",
      "| 97.5|  7.6|      7.2|  9.7|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FIltering\n",
    "ds[ds['Newspaper'] < 20].show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|120.2| 19.6|     11.6| 13.2|\n",
      "|214.7|   24|        4| 17.4|\n",
      "|147.3| 23.9|     19.1| 14.6|\n",
      "|262.9|  3.5|     19.5|   12|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple conditions\n",
    "ds[(ds['Newspaper'] < 20) & (ds['TV'] > 100)].show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+--------------------+\n",
      "|   TV|Radio|Newspaper|Sales|             tv_norm|\n",
      "+-----+-----+---------+-----+--------------------+\n",
      "|230.1| 37.8|     69.2| 22.1|0.007824268493802813|\n",
      "| 44.5| 39.3|     45.1| 10.4|0.001513167961643...|\n",
      "| 17.2| 45.9|     69.3|  9.3|5.848649200061207E-4|\n",
      "|151.5| 41.3|     58.5| 18.5|0.005151571824472517|\n",
      "|180.8| 10.8|     58.4| 12.9|0.006147882414948061|\n",
      "|  8.7| 48.9|       75|  7.2|2.958328374449564E-4|\n",
      "| 57.5| 32.8|     23.5| 11.8|0.001955217029090...|\n",
      "|120.2| 19.6|     11.6| 13.2|0.004087253685159...|\n",
      "|  8.6|  2.1|        1|  4.8|2.924324600030603...|\n",
      "|199.8|  2.6|     21.2| 10.6| 0.00679395412890831|\n",
      "| 66.1|  5.8|     24.2|  8.6|0.002247649489093...|\n",
      "|214.7|   24|        4| 17.4|0.007300610367750821|\n",
      "| 23.8| 35.1|     65.9|  9.2|8.092898311712601E-4|\n",
      "| 97.5|  7.6|      7.2|  9.7|0.003315368005848...|\n",
      "|204.1| 32.9|       46|   19| 0.00694017035890984|\n",
      "|195.4| 47.7|     52.9| 22.4|0.006644337521464884|\n",
      "| 67.8| 36.6|      114| 12.5|0.002305455905605...|\n",
      "|281.4| 39.6|     55.8| 24.4|0.009568662121495486|\n",
      "| 69.2| 20.5|     18.3| 11.3|0.002353061189792...|\n",
      "|147.3| 23.9|     19.1| 14.6|0.005008755971912884|\n",
      "|218.4| 27.7|     53.4|   18|0.007426424333100976|\n",
      "|237.4|  5.1|     23.5| 12.5|0.008072496047061225|\n",
      "| 13.2| 15.9|     49.6|  5.6|4.488498223302787E-4|\n",
      "|228.3| 16.9|     26.2| 15.5|0.007763061699848684|\n",
      "| 62.3| 12.6|     18.3|  9.7|0.002118435146301...|\n",
      "|262.9|  3.5|     19.5|   12|0.008939592294744716|\n",
      "|142.9| 29.3|     12.6|   15|0.004859139364469...|\n",
      "|240.1| 16.7|     22.9| 15.9|0.008164306237992419|\n",
      "|248.8| 27.1|     22.9| 18.9|0.008460139075437375|\n",
      "| 70.6|   16|     40.8| 10.5|0.002400666473978...|\n",
      "|292.9| 28.3|     43.2| 21.4|0.009959705527313532|\n",
      "|112.9| 17.4|     38.6| 11.9|0.003839026131900...|\n",
      "| 97.2|  1.5|       30|  9.6|0.003305166873522...|\n",
      "|265.6|   20|      0.3| 17.4|0.009031402485675912|\n",
      "| 95.7|  1.4|      7.4|  9.5|0.003254161211894521|\n",
      "|290.7|  4.1|      8.5| 12.8|0.009884897223591819|\n",
      "|266.9| 43.8|        5| 25.4|0.009075607392420559|\n",
      "| 74.7| 49.4|     45.7| 14.7| 0.00254008194909635|\n",
      "| 43.1| 26.7|     35.1| 10.1|0.001465562677457...|\n",
      "|  228| 37.7|       32| 21.5|0.007752860567522996|\n",
      "|202.5| 22.3|     31.6| 16.6|0.006885764319839503|\n",
      "|  177| 33.4|     38.7| 17.1| 0.00601866807215601|\n",
      "|293.6| 27.7|      1.8| 20.7|0.009983508169406807|\n",
      "|206.9|  8.4|     26.4| 12.9|0.007035380927282929|\n",
      "| 25.1| 25.7|     43.3|  8.5|8.534947379159088E-4|\n",
      "|175.1| 22.5|     31.5| 14.9|0.005954060900759...|\n",
      "| 89.7|  9.9|     35.7| 10.6|0.003050138565380758|\n",
      "|239.9| 41.5|     18.5| 23.2|0.008157505483108627|\n",
      "|227.2| 15.8|     49.9| 14.8|0.007725657547987827|\n",
      "| 66.9| 11.7|     36.8|  9.7|0.002274852508628...|\n",
      "|199.8|  3.1|     34.6| 11.4| 0.00679395412890831|\n",
      "|100.4|  9.6|      3.6| 10.7|0.003413978951663...|\n",
      "|216.4| 41.7|     39.6| 22.6|0.007358416784263054|\n",
      "|182.6| 46.2|     58.7| 21.2|0.006209089208902189|\n",
      "|262.7| 28.8|     15.9| 20.2|0.008932791539860926|\n",
      "|198.9| 49.4|       60| 23.7|0.006763350731931245|\n",
      "|  7.3| 28.1|     41.4|  5.5|2.482275532584117E-4|\n",
      "|136.2| 19.2|     16.6| 13.2|0.004631314075862421|\n",
      "|210.8| 49.6|     37.7| 23.8|0.007167995647516876|\n",
      "|210.7| 29.5|      9.3| 18.4|0.007164595270074979|\n",
      "| 53.5|    2|     21.4|  8.1|0.001819201931414...|\n",
      "|261.3| 42.7|     54.7| 24.2| 0.00888518625567438|\n",
      "|239.3| 15.5|     27.3| 15.7| 0.00813710321845725|\n",
      "|102.7| 29.6|      8.4|   14|0.003492187632827...|\n",
      "|131.1| 42.8|     28.9|   18|0.004457894826325723|\n",
      "|   69|  9.3|      0.9|  9.3|0.002346260434908275|\n",
      "| 31.5| 24.6|      2.2|  9.5|0.001071118894197256|\n",
      "|139.3| 14.5|     10.2| 13.4|  0.0047367257765612|\n",
      "|237.4| 27.5|       11| 18.9|0.008072496047061225|\n",
      "|216.8| 43.9|     27.2| 22.3|0.007372018294030...|\n",
      "|199.1| 30.6|     38.7| 18.3|0.006770151486815037|\n",
      "|109.8| 14.3|     31.7| 12.4|0.003733614431201864|\n",
      "| 26.8|   33|     19.3|  8.8|9.113011544281417E-4|\n",
      "|129.4|  5.7|     31.3|   11| 0.00440008840981349|\n",
      "|213.4| 24.6|     13.1|   17|0.007256405461006173|\n",
      "| 16.9| 43.7|     89.4|  8.7|5.746637876804326E-4|\n",
      "| 27.5|  1.6|     20.7|  6.9| 9.35103796521414E-4|\n",
      "|120.5| 28.5|     14.2| 14.2|0.004097454817484742|\n",
      "|  5.4| 29.9|      9.4|  5.3|1.836203818623867...|\n",
      "|  116|  7.7|     23.1|   11|0.003944437832599419|\n",
      "| 76.4| 26.7|     22.3| 11.8|0.002597888365608583|\n",
      "|239.8|  4.1|     36.9| 12.3| 0.00815410510566673|\n",
      "| 75.3| 20.3|     32.5| 11.3|0.002560484213747726|\n",
      "| 68.4| 44.5|     35.6| 13.6|0.002325858170256899|\n",
      "|213.5|   43|     33.8| 21.7|0.007259805838448069|\n",
      "|193.2| 18.4|     65.7| 15.2| 0.00656952921774317|\n",
      "| 76.3| 27.5|       16|   12|0.002594487988166687|\n",
      "|110.7| 40.6|     63.2|   16|0.003764217828178...|\n",
      "| 88.3| 25.5|     73.4| 12.9|0.003002533281194213|\n",
      "|109.8| 47.8|     51.4| 16.7|0.003733614431201864|\n",
      "|134.3|  4.9|      9.3| 11.2|0.004566706904466397|\n",
      "| 28.6|  1.5|       33|  7.3|9.725079483822706E-4|\n",
      "|217.7| 33.5|       59| 19.4|0.007402621691007702|\n",
      "|250.9| 36.5|     72.3| 22.2|0.008531547001717191|\n",
      "|107.4|   14|     10.9| 11.5|0.003652005372596359|\n",
      "|163.3| 31.6|     52.9| 16.9|0.005552816362616252|\n",
      "|197.6|  3.5|      5.9| 11.7|0.006719145825186596|\n",
      "|184.9|   21|       22| 15.5|0.006287297890065799|\n",
      "|289.7| 42.3|     51.2| 25.4| 0.00985089344917286|\n",
      "|135.2| 41.7|     45.9| 17.2|0.004597310301443461|\n",
      "+-----+-----+---------+-----+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new column\n",
    "import pyspark.sql.functions as F \n",
    "ds.withColumn('tv_norm', ds['Tv'] / ds.groupBy().agg(F.sum('TV')).collect()[0][0]).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+----+\n",
      "|   TV|Radio|Newspaper|Sales|cond|\n",
      "+-----+-----+---------+-----+----+\n",
      "|230.1| 37.8|     69.2| 22.1|   1|\n",
      "| 44.5| 39.3|     45.1| 10.4|   3|\n",
      "| 17.2| 45.9|     69.3|  9.3|   3|\n",
      "|151.5| 41.3|     58.5| 18.5|   2|\n",
      "+-----+-----+---------+-----+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New column conditions\n",
    "ds.withColumn('cond', F.when((ds['TV'] > 100) & (ds['Radio'] < 40), 1).when(ds['Sales'] > 10, 2).otherwise(3)).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+------------------+\n",
      "|   TV|Radio|Newspaper|Sales|            log_TV|\n",
      "+-----+-----+---------+-----+------------------+\n",
      "|230.1| 37.8|     69.2| 22.1|  5.43851399704132|\n",
      "| 44.5| 39.3|     45.1| 10.4|3.7954891891721947|\n",
      "| 17.2| 45.9|     69.3|  9.3|2.8449093838194073|\n",
      "|151.5| 41.3|     58.5| 18.5| 5.020585624949424|\n",
      "+-----+-----+---------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumn('log_TV', F.log(ds['TV'])).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+-----+\n",
      "|   TV|Radio|Newspaper|Sales|TV+10|\n",
      "+-----+-----+---------+-----+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|240.1|\n",
      "| 44.5| 39.3|     45.1| 10.4| 54.5|\n",
      "| 17.2| 45.9|     69.3|  9.3| 27.2|\n",
      "|151.5| 41.3|     58.5| 18.5|161.5|\n",
      "+-----+-----+---------+-----+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumn('TV+10', ds['TV'] + 10).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  A0  B0  C0  D0\n",
       "1  A1  B1  C1  D1\n",
       "2  A2  B2  C2  D2\n",
       "3  A3  B3  C3  D3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftp = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "leftp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A1</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A6</td>\n",
       "      <td>B6</td>\n",
       "      <td>C6</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A7</td>\n",
       "      <td>B7</td>\n",
       "      <td>C7</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   F   G   H\n",
       "4  A0  B4  C4  D4\n",
       "5  A1  B5  C5  D5\n",
       "6  A6  B6  C6  D6\n",
       "7  A7  B7  C7  D7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightp = pd.DataFrame({'A': ['A0', 'A1', 'A6', 'A7'],\n",
    "                       'F': ['B4', 'B5', 'B6', 'B7'],\n",
    "                       'G': ['C4', 'C5', 'C6', 'C7'],\n",
    "                       'H': ['D4', 'D5', 'D6', 'D7']},\n",
    "                       index=[4, 5, 6, 7])\n",
    "rightp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts = spark.createDataFrame(leftp)\n",
    "rights = spark.createDataFrame(rightp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+----+----+----+\n",
      "|  A|  B|  C|  D|   F|   G|   H|\n",
      "+---+---+---+---+----+----+----+\n",
      "| A0| B0| C0| D0|  B4|  C4|  D4|\n",
      "| A1| B1| C1| D1|  B5|  C5|  D5|\n",
      "| A2| B2| C2| D2|null|null|null|\n",
      "| A3| B3| C3| D3|null|null|null|\n",
      "+---+---+---+---+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left join\n",
    "lefts.join(rights, on= 'A', how= 'left').orderBy('A', ascending= True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+---+---+---+\n",
      "|  A|   B|   C|   D|  F|  G|  H|\n",
      "+---+----+----+----+---+---+---+\n",
      "| A0|  B0|  C0|  D0| B4| C4| D4|\n",
      "| A1|  B1|  C1|  D1| B5| C5| D5|\n",
      "| A6|null|null|null| B6| C6| D6|\n",
      "| A7|null|null|null| B7| C7| D7|\n",
      "+---+----+----+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Right join\n",
    "lefts.join(rights, on='A', how= 'right').orderBy('A', ascending= True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "|  A|  B|  C|  D|  F|  G|  H|\n",
      "+---+---+---+---+---+---+---+\n",
      "| A0| B0| C0| D0| B4| C4| D4|\n",
      "| A1| B1| C1| D1| B5| C5| D5|\n",
      "+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner Join\n",
    "lefts.join(rights, on='A', how='inner').orderBy('A', ascending= True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+----+----+\n",
      "|  A|   B|   C|   D|   F|   G|   H|\n",
      "+---+----+----+----+----+----+----+\n",
      "| A0|  B0|  C0|  D0|  B4|  C4|  D4|\n",
      "| A1|  B1|  C1|  D1|  B5|  C5|  D5|\n",
      "| A2|  B2|  C2|  D2|null|null|null|\n",
      "| A3|  B3|  C3|  D3|null|null|null|\n",
      "| A6|null|null|null|  B6|  C6|  D6|\n",
      "| A7|null|null|null|  B7|  C7|  D7|\n",
      "+---+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Full join\n",
    "lefts.join(rights, on='A', how= 'full').orderBy('A', ascending= True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   a|   2|   3|\n",
      "|   b|   5|   6|\n",
      "|   c|   8|   9|\n",
      "|   a|   2|   3|\n",
      "|   b|   5|   6|\n",
      "|   c|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9),\n",
    "           ('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9)]\n",
    "col_name = ['col1', 'col2', 'col3']\n",
    "ds = spark.createDataFrame(my_list,schema=col_name)\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+------+\n",
      "|col1|col2|col3|concat|\n",
      "+----+----+----+------+\n",
      "|   a|   2|   3|    a2|\n",
      "|   b|   5|   6|    b5|\n",
      "|   c|   8|   9|    c8|\n",
      "|   a|   2|   3|    a2|\n",
      "|   b|   5|   6|    b5|\n",
      "|   c|   8|   9|    c8|\n",
      "+----+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumn('concat', F.concat('col1', 'col2')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---------+\n",
      "|col1|min(col2)|avg(col3)|\n",
      "+----+---------+---------+\n",
      "|   a|        2|      3.0|\n",
      "|   b|        5|      6.0|\n",
      "|   c|        8|      9.0|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupby\n",
    "ds.groupBy(['col1']).agg({'col2' : 'min',\n",
    "                          'col3' : 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+\n",
      "|col1|   2|   5|   8|\n",
      "+----+----+----+----+\n",
      "|   c|null|null|  18|\n",
      "|   b|null|  12|null|\n",
      "|   a|   6|null|null|\n",
      "+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pivot\n",
    "ds.groupBy(['col1']).pivot('col2').sum('col3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  a|  m|  1|\n",
      "|  b|  m|  2|\n",
      "|  c|  n|  3|\n",
      "|  d|  n|  6|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window\n",
    "d = {'A':['a','b','c','d'],'B':['m','m','n','n'],'C':[1,2,3,6]}\n",
    "ds = spark.createDataFrame(pd.DataFrame(d))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----+\n",
      "|  A|  B|  C|rank|\n",
      "+---+---+---+----+\n",
      "|  d|  n|  6|   1|\n",
      "|  c|  n|  3|   2|\n",
      "|  b|  m|  2|   3|\n",
      "|  a|  m|  1|   4|\n",
      "+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# normal rank\n",
    "w = Window.orderBy(ds['C'].desc())\n",
    "ds = ds.withColumn('rank', F.rank().over(w))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----+\n",
      "|  A|  B|  C|rank|\n",
      "+---+---+---+----+\n",
      "|  a|  m|  1|   1|\n",
      "|  b|  m|  2|   2|\n",
      "|  c|  n|  3|   1|\n",
      "|  d|  n|  6|   2|\n",
      "+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rank partitionBy('B')\n",
    "w = Window.partitionBy('B').orderBy(ds['C'])\n",
    "ds = ds.withColumn('rank', F.rank().over(w))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Score|\n",
      "+---+-----+\n",
      "|  1|  4.0|\n",
      "|  2|  4.0|\n",
      "|  3| 3.85|\n",
      "|  4| 3.65|\n",
      "|  5| 3.65|\n",
      "|  6|  3.5|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rank vs Dense_rank\n",
    "d ={'Id':[1,2,3,4,5,6],\n",
    "    'Score': [4.00, 4.00, 3.85, 3.65, 3.65, 3.50]}\n",
    "\n",
    "ds = spark.createDataFrame(pd.DataFrame(d))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+\n",
      "| Id|Score|Rank_dense|Rank|\n",
      "+---+-----+----------+----+\n",
      "|  1|  4.0|         1|   1|\n",
      "|  2|  4.0|         1|   1|\n",
      "|  3| 3.85|         2|   3|\n",
      "|  4| 3.65|         3|   4|\n",
      "|  5| 3.65|         3|   4|\n",
      "|  6|  3.5|         4|   6|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = Window.orderBy(ds['Score'].desc())\n",
    "ds = ds.withColumn('Rank_dense', F.dense_rank().over(w))\n",
    "ds = ds.withColumn('Rank', F.rank().over(w))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|    Date|Stock|Price|\n",
      "+--------+-----+-----+\n",
      "|8/1/2022|  VNM|73500|\n",
      "|8/2/2022|  VNM|73400|\n",
      "|8/3/2022|  VNM|73400|\n",
      "|8/4/2022|  VNM|73300|\n",
      "|8/5/2022|  VNM|72600|\n",
      "+--------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_data = spark.read.csv(\"Stock_data.csv\", header= True )\n",
    "stock_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Date|\n",
      "+---------+\n",
      "| 8/9/2022|\n",
      "| 8/2/2022|\n",
      "| 8/4/2022|\n",
      "|8/14/2022|\n",
      "| 8/5/2022|\n",
      "|8/12/2022|\n",
      "|8/11/2022|\n",
      "|8/10/2022|\n",
      "| 8/3/2022|\n",
      "|8/13/2022|\n",
      "| 8/7/2022|\n",
      "| 8/6/2022|\n",
      "| 8/8/2022|\n",
      "| 8/1/2022|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_data.select('Date').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Date|\n",
      "+---------+\n",
      "| 8/9/2022|\n",
      "| 8/2/2022|\n",
      "| 8/4/2022|\n",
      "|8/14/2022|\n",
      "| 8/5/2022|\n",
      "|8/12/2022|\n",
      "|8/11/2022|\n",
      "|8/10/2022|\n",
      "| 8/3/2022|\n",
      "|8/13/2022|\n",
      "| 8/7/2022|\n",
      "| 8/6/2022|\n",
      "| 8/8/2022|\n",
      "| 8/1/2022|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_data.select('Date').orderBy('Date').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Stock|\n",
      "+-----+\n",
      "|  ROS|\n",
      "|  VCB|\n",
      "|  VNM|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_data.select('Stock').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+\n",
      "|     Date|ROS_Price|VCB_Price|VNM_Price|\n",
      "+---------+---------+---------+---------+\n",
      "| 8/1/2022|     2970|    77000|    73500|\n",
      "| 8/2/2022|     3170|    78900|    73400|\n",
      "| 8/3/2022|     2950|    79500|    73400|\n",
      "| 8/4/2022|     2850|    82500|    73300|\n",
      "| 8/5/2022|     2800|    82000|    72600|\n",
      "| 8/6/2022|     2705|    82000|    72400|\n",
      "| 8/7/2022|     2705|    82000|    72400|\n",
      "| 8/8/2022|     2610|    82000|    72200|\n",
      "| 8/9/2022|     2480|    80800|    72000|\n",
      "|8/10/2022|     2600|    80500|    72500|\n",
      "|8/11/2022|     2510|    81500|    71100|\n",
      "|8/12/2022|     2510|    81600|    71900|\n",
      "|8/13/2022|     2510|    81800|    71500|\n",
      "|8/14/2022|     2510|    81500|    71800|\n",
      "+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ROS = stock_data.filter(stock_data.Stock == 'ROS')\n",
    "VCB = stock_data.filter(stock_data.Stock == 'VCB')\n",
    "VNM = stock_data.filter(stock_data.Stock == 'VNM')\n",
    "\n",
    "ROS = ROS.select('Date','Price')\n",
    "VCB = VCB.select('Date','Price')\n",
    "VNM = VNM.select('Date','Price')\n",
    "\n",
    "ROS = ROS.withColumnRenamed('Price','ROS_Price')\n",
    "VCB = VCB.withColumnRenamed('Price','VCB_Price')\n",
    "VNM = VNM.withColumnRenamed('Price','VNM_Price')\n",
    "\n",
    "output = ROS.join(VCB, on= 'Date', how= 'left').join(VNM, on= 'Date', how= 'left')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+-----+\n",
      "|     Date| ROS|  VCB|  VNM|\n",
      "+---------+----+-----+-----+\n",
      "| 8/9/2022|2480|80800|72000|\n",
      "| 8/4/2022|2850|82500|73300|\n",
      "| 8/2/2022|3170|78900|73400|\n",
      "|8/14/2022|2510|81500|71800|\n",
      "| 8/5/2022|2800|82000|72600|\n",
      "|8/12/2022|2510|81600|71900|\n",
      "|8/11/2022|2510|81500|71100|\n",
      "|8/10/2022|2600|80500|72500|\n",
      "| 8/3/2022|2950|79500|73400|\n",
      "|8/13/2022|2510|81800|71500|\n",
      "| 8/7/2022|2705|82000|72400|\n",
      "| 8/6/2022|2705|82000|72400|\n",
      "| 8/8/2022|2610|82000|72200|\n",
      "| 8/1/2022|2970|77000|73500|\n",
      "+---------+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_data = stock_data.withColumn('Price',stock_data['Price'].cast('int'))\n",
    "stock_data.groupBy('Date').pivot('Stock').sum('Price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.4.0-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "stock_data.registerTempTable('stock_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+---------+\n",
      "|     Date|Stock|Price|yesterday|\n",
      "+---------+-----+-----+---------+\n",
      "| 8/1/2022|  ROS| 2970|     null|\n",
      "|8/10/2022|  ROS| 2600|     2970|\n",
      "|8/11/2022|  ROS| 2510|     2600|\n",
      "|8/12/2022|  ROS| 2510|     2510|\n",
      "|8/13/2022|  ROS| 2510|     2510|\n",
      "|8/14/2022|  ROS| 2510|     2510|\n",
      "| 8/2/2022|  ROS| 3170|     2510|\n",
      "| 8/3/2022|  ROS| 2950|     3170|\n",
      "| 8/4/2022|  ROS| 2850|     2950|\n",
      "| 8/5/2022|  ROS| 2800|     2850|\n",
      "+---------+-----+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * , lag(Price, 1) over (partition by Stock order by Date) as yesterday from stock_data').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
